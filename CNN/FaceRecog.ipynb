{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Variables\n",
    "TRAIN_THRESHOLD = 0.8\n",
    "DROPNAN = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "training = pd.read_csv('./ressources/training/training.csv')\n",
    "#On enleve les NaN\n",
    "if DROPNAN:\n",
    "    training = training.dropna()\n",
    "else:\n",
    "    training.fillna(method = 'ffill',inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66.03356391 39.00227368 30.22700752 ... 72.93545865 43.13070677\n",
      "  84.48577444]\n",
      " [64.33293617 34.9700766  29.9492766  ... 70.26655319 45.46791489\n",
      "  85.48017021]\n",
      " [65.05705263 34.90964211 30.90378947 ... 70.19178947 47.27494737\n",
      "  78.65936842]\n",
      " ...\n",
      " [66.69073171 36.84522146 31.66641951 ... 75.96359236 49.46257171\n",
      "  78.11712   ]\n",
      " [70.96508235 39.85366588 30.54328471 ... 75.96359236 50.06518588\n",
      "  79.58644706]\n",
      " [66.93831111 43.42450963 31.09605926 ... 75.96359236 45.90048\n",
      "  82.7730963 ]]\n"
     ]
    }
   ],
   "source": [
    "X = training.Image.values\n",
    "del training['Image']\n",
    "Y = training.values\n",
    "print(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7049/7049 [00:11<00:00, 616.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(7049, 96, 96, 1)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "for i in tqdm(X):\n",
    "    q = [int(j) for j in i.split()]\n",
    "    x.append(q)\n",
    "len(x)\n",
    "\n",
    "x = np.array(x)\n",
    "x = x.reshape(X.shape[0], 96,96,1)\n",
    "x  = x/255.0\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(5639, 96, 96, 1)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = tts(x,Y,random_state = 69,test_size = 1-TRAIN_THRESHOLD)\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-42752211cbb1>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign to variable block1_conv1/kernel:0 due to variable shape (3, 3, 1, 64) and value shape (64, 3, 3, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-4aba15c0da10>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m baseModel = VGG16(weights=\"imagenet\", include_top=False,\n\u001B[1;32m----> 2\u001B[1;33m \tinput_tensor=Input(shape=(96, 96, 1)))\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mheadModel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbaseModel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mheadModel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFlatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"flatten\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mheadModel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\LIFPROJET_AM3\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\vgg16.py\u001B[0m in \u001B[0;36mVGG16\u001B[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001B[0m\n\u001B[0;32m    220\u001B[0m           \u001B[0mcache_subdir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'models'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m           file_hash='6d6bbae143d832006294945121d1f1fc')\n\u001B[1;32m--> 222\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweights_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    223\u001B[0m   \u001B[1;32melif\u001B[0m \u001B[0mweights\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\LIFPROJET_AM3\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mload_weights\u001B[1;34m(self, filepath, by_name, skip_mismatch, options)\u001B[0m\n\u001B[0;32m   2232\u001B[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001B[0;32m   2233\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2234\u001B[1;33m         \u001B[0mhdf5_format\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_weights_from_hdf5_group\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2235\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2236\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_updated_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\LIFPROJET_AM3\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001B[0m in \u001B[0;36mload_weights_from_hdf5_group\u001B[1;34m(f, layers)\u001B[0m\n\u001B[0;32m    708\u001B[0m                        str(len(weight_values)) + ' elements.')\n\u001B[0;32m    709\u001B[0m     \u001B[0mweight_value_tuples\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msymbolic_weights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight_values\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 710\u001B[1;33m   \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_set_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight_value_tuples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    711\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    712\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\LIFPROJET_AM3\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\LIFPROJET_AM3\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001B[0m in \u001B[0;36mbatch_set_value\u001B[1;34m(tuples)\u001B[0m\n\u001B[0;32m   3704\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly_outside_functions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3705\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtuples\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3706\u001B[1;33m       \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massign\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3707\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3708\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mget_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_default\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\LIFPROJET_AM3\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001B[0m in \u001B[0;36massign\u001B[1;34m(self, value, use_locking, name, read_value)\u001B[0m\n\u001B[0;32m    889\u001B[0m             (\"Cannot assign to variable%s due to variable shape %s and value \"\n\u001B[0;32m    890\u001B[0m              \"shape %s are incompatible\") %\n\u001B[1;32m--> 891\u001B[1;33m             (tensor_name, self._shape, value_tensor.shape))\n\u001B[0m\u001B[0;32m    892\u001B[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001B[0;32m    893\u001B[0m           self.handle, value_tensor, name=name)\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot assign to variable block1_conv1/kernel:0 due to variable shape (3, 3, 1, 64) and value shape (64, 3, 3, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(96, 96, 1)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.4)(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)\n",
    "headModel = Dense(len(y_train[0]), activation=\"softmax\")(headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "model.compile(optimizer = 'adam',loss = 'mean_squared_error', metrics = ['mae','acc'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model.fit(x_train,y_train,batch_size=256, epochs=50,validation_data=(x_test,y_test))\n",
    "model.save_weights(\"./checkpoints/CNN1.ckpt\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-359a0bdc",
   "language": "python",
   "display_name": "PyCharm (LIFPROJET_AM3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}